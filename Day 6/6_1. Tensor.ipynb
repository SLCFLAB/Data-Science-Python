{
  "cells": [
  {
   "cell_type": "markdown",
   "id": "5c7a15f6",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/SLCFLAB/Data-Science-Python/blob/main/Day%206/6_1.%20Tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref: https://github.com/Harry24k/Pytorch-Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTi7s_Zx7q-5"
   },
   "source": [
    "# How to use Colab?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOYj4eVv78P3"
   },
   "source": [
    "Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud.\n",
    "\n",
    "With Colaboratory you can write and execute code, save and share your analyses, and access powerful computing resources, all for free from your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJ0xmENaPCUV"
   },
   "source": [
    "Advantages\n",
    "\n",
    "- The best thing is that it is free!\n",
    "- It gives you costly GPUs and working envriornment, independent of what personal machine you are using.\n",
    "- It also runs on Google servers using virtual machines and you don’t need to install any packages, which sometimes create difficulty you are using different operating systems such as MAC, Windows, and Linux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXMjrr-lidJq"
   },
   "source": [
    "### Hotkeys (change as you want)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLlLU_Aoi8IK"
   },
   "source": [
    "| hotkey | action |\n",
    "| --- | --- |\n",
    "| ctrl + M H | Open hotkey configuration |\n",
    "| ctrl + O | Open note |\n",
    "| ctrl + S | Save note |\n",
    "| ctrl + F9 | Run all cells |\n",
    "| ctrl + shift + enter | Run cell |\n",
    "| shift + enter | Run cell and move on to the next |\n",
    "| alt + enter | Run cell and add a new one below |\n",
    "| ctrl + M I | Stop running execution |\n",
    "| ctrl + M A | Add new code cell above |\n",
    "| ctrl + M B | Add new code cell below |\n",
    "| ctrl + M D | Delete cell |\n",
    "| ctrl + M K | Move cell up |\n",
    "| ctrl + M J | Move cell down |\n",
    "| ctrl + M Y | Change to code cell |\n",
    "| ctrl + M M | Change to markdown cell |\n",
    "| ctrl + M Z | Undo last cell execution |\n",
    "| ctrl + H | Search |\n",
    "| ctrl + / | Comment out or undo |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVbAfCjZsf9D"
   },
   "source": [
    "### Terminal commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2030,
     "status": "ok",
     "timestamp": 1629628881856,
     "user": {
      "displayName": "jinsup lee",
      "photoUrl": "",
      "userId": "18085598551088602565"
     },
     "user_tz": -540
    },
    "id": "I-37xARkqKFA",
    "outputId": "41fed906-3545-4d8a-bc30-b3d53dc8766b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ubuntu 18.04.5 LTS\n"
     ]
    }
   ],
   "source": [
    "# Get OS info\n",
    "!cat /etc/issue.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1629628881858,
     "user": {
      "displayName": "jinsup lee",
      "photoUrl": "",
      "userId": "18085598551088602565"
     },
     "user_tz": -540
    },
    "id": "h1oXSy-RvGkC",
    "outputId": "2a7dc6bc-6bb2-4fea-9e6a-113666cfb520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processor\t: 0\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "cpu cores\t: 1\n",
      "processor\t: 1\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "cpu cores\t: 1\n",
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:            12G        536M        9.9G        1.2M        2.2G         11G\n",
      "Swap:            0B          0B          0B\n",
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay          69G   38G   32G  55% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
      "shm             5.8G     0  5.8G   0% /dev/shm\n",
      "/dev/sda1        76G   42G   35G  55% /opt/bin/.nvidia\n",
      "tmpfs           6.4G   36K  6.4G   1% /var/colab\n",
      "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
      "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
      "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "# Get CPU info\n",
    "!cat /proc/cpuinfo | grep 'processor\\|model name\\|cpu cores'\n",
    "# Get memory info\n",
    "!free -h\n",
    "# Get disk info\n",
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1629628884152,
     "user": {
      "displayName": "jinsup lee",
      "photoUrl": "",
      "userId": "18085598551088602565"
     },
     "user_tz": -540
    },
    "id": "bnwLlgJ_gkAI",
    "outputId": "66e2db86-6b4c-4fa4-873b-1c02ec6a7685"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 22 10:41:23 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   39C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Get GPU info\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1629628886161,
     "user": {
      "displayName": "jinsup lee",
      "photoUrl": "",
      "userId": "18085598551088602565"
     },
     "user_tz": -540
    },
    "id": "o40n39H4r4gR",
    "outputId": "0a7e0add-be28-4150-9a57-02f9dd04d5a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.11\n"
     ]
    }
   ],
   "source": [
    "# Get python version\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1629628887766,
     "user": {
      "displayName": "jinsup lee",
      "photoUrl": "",
      "userId": "18085598551088602565"
     },
     "user_tz": -540
    },
    "id": "_vfTvu3_-lb8",
    "outputId": "6dc8bf9d-9b72-4a9a-e317-b9d9f6aa8ff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "/root\n"
     ]
    }
   ],
   "source": [
    "# Get current directory\n",
    "!pwd\n",
    "%cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1629628888124,
     "user": {
      "displayName": "jinsup lee",
      "photoUrl": "",
      "userId": "18085598551088602565"
     },
     "user_tz": -540
    },
    "id": "vnJhNcnO-7X0",
    "outputId": "d19cbfe1-5d97-44c5-c329-d738cfc56cbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 64K\n",
      "drwx------ 1 root root 4.0K Aug 22 10:28 .\n",
      "drwxr-xr-x 1 root root 4.0K Aug 22 10:27 ..\n",
      "-r-xr-xr-x 1 root root 1.2K Jan  1  2000 .bashrc\n",
      "drwxr-xr-x 1 root root 4.0K Aug 18 13:21 .cache\n",
      "drwxr-xr-x 1 root root 4.0K Aug 18 13:19 .config\n",
      "drwxr-xr-x 3 root root 4.0K Aug 17 13:20 .gsutil\n",
      "drwxr-xr-x 1 root root 4.0K Aug 18 13:19 .ipython\n",
      "drwx------ 2 root root 4.0K Aug 18 13:19 .jupyter\n",
      "drwxr-xr-x 2 root root 4.0K Aug 22 10:28 .keras\n",
      "drwx------ 1 root root 4.0K Aug 18 13:19 .local\n",
      "drwxr-xr-x 4 root root 4.0K Aug 18 13:19 .npm\n",
      "-rw-r--r-- 1 root root  148 Aug 17  2015 .profile\n",
      "-r-xr-xr-x 1 root root  254 Jan  1  2000 .tmux.conf\n"
     ]
    }
   ],
   "source": [
    "# Get files/folders list\n",
    "!ls -lah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1629628889662,
     "user": {
      "displayName": "jinsup lee",
      "photoUrl": "",
      "userId": "18085598551088602565"
     },
     "user_tz": -540
    },
    "id": "SanL9vJZOk5v",
    "outputId": "eae4c4e7-ff3f-4a39-dba4-e41207f1aba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: missing file operand\n",
      "Try 'mv --help' for more information.\n",
      "cp: missing file operand\n",
      "Try 'cp --help' for more information.\n"
     ]
    }
   ],
   "source": [
    "!mv\n",
    "!cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2825,
     "status": "ok",
     "timestamp": 1629628893953,
     "user": {
      "displayName": "jinsup lee",
      "photoUrl": "",
      "userId": "18085598551088602565"
     },
     "user_tz": -540
    },
    "id": "Llw0ZPAKoMZi",
    "outputId": "d940dce3-9e95-4b39-e372-3cb008a3d9d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 1.9.0+cu102\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /usr/local/lib/python3.7/dist-packages\n",
      "Requires: typing-extensions\n",
      "Required-by: torchvision, torchtext, fastai\n"
     ]
    }
   ],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjcTMg3s7sM4"
   },
   "source": [
    "### File I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 39,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "executionInfo": {
     "elapsed": 5620,
     "status": "ok",
     "timestamp": 1629628901470,
     "user": {
      "displayName": "jinsup lee",
      "photoUrl": "",
      "userId": "18085598551088602565"
     },
     "user_tz": -540
    },
    "id": "ICWGHmOhuFUI",
    "outputId": "c66d8284-d390-4bf0-e600-38f599cdb7d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-7f80f93c-fad4-4761-942f-412c43baa1fe\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-7f80f93c-fad4-4761-942f-412c43baa1fe\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload file to Colab workspace\n",
    "# [NOTE] Uploaded files will be gone when runtime resets\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for f in uploaded.keys():\n",
    "    print('User uploaded file \"{}\" at \"{}\"'.format(f, os.getcwd()))\n",
    "\n",
    "# Or simply open file tab then drag-and-drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "executionInfo": {
     "elapsed": 367,
     "status": "error",
     "timestamp": 1629628904074,
     "user": {
      "displayName": "jinsup lee",
      "photoUrl": "",
      "userId": "18085598551088602565"
     },
     "user_tz": -540
    },
    "id": "AtBKyVEjAJu4",
    "outputId": "07856b91-f7af-4be1-db85-e36f2f7daa55"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-10-0cb3f8e5d1c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0;31m# Download file from Colab workspace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[0;31m# [NOTE] Enable third party cookies and use Chrome browser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./sample_data/mnist_train_small.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      5\u001b[0m \u001b[0;31m# Or simply open file tab and right click a file then download <-- Recommended\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n",
      "\u001b[1;32m    141\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 143\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    145\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: ./sample_data/mnist_train_small.csv"
     ]
    }
   ],
   "source": [
    "# Download file from Colab workspace\n",
    "# [NOTE] Enable third party cookies and use Chrome browser\n",
    "files.download('./sample_data/mnist_train_small.csv')\n",
    "\n",
    "# Or simply open file tab and right click a file then download <-- Recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22861,
     "status": "ok",
     "timestamp": 1629628928627,
     "user": {
      "displayName": "jinsup lee",
      "photoUrl": "",
      "userId": "18085598551088602565"
     },
     "user_tz": -540
    },
    "id": "j4BaBcpeDGpO",
    "outputId": "f90558b5-b71b-49f6-8f91-eca7594c59df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google drive\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Tensor Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.5729e+32, 8.7861e-43, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "#Tensor의 기초적 선언\n",
    "#torch.FloatTensor와 같음\n",
    "# x = torch.Tensor(행, 열)\n",
    "x = torch.Tensor(2, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Type :  <class 'torch.Tensor'>\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#Tesnor의 정보 확인\n",
    "print(\"Tensor Type : \", type(x))\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size()) # x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Tensor with characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#0으로 채워진 Tensor 선언\n",
    "x = torch.zeros(2, 3)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]], dtype=torch.int32)\n",
      "Tensor Type :  torch.IntTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2,3, dtype=torch.int32)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#1로 채워진 Tensor 선언\n",
    "x = torch.ones(2, 3)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2038, 0.8930, 0.0199],\n",
      "        [0.4733, 0.0485, 0.4502]])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#0, 1 사이의 랜덤 숫자로 채워진 Tensor 선언\n",
    "x = torch.rand(2, 3)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5146,  0.1675,  0.2127],\n",
      "        [-0.1943,  1.0772, -2.1785]])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#평균이 0이고 분산이 1을 따르는 정규분포에서 추출된 값으로 채워진 Tensor 선언\n",
    "x = torch.randn(2, 3)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.]])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#정방행렬과 같은 Tensor 선언\n",
    "x = torch.eye(2, 3)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.5000, 1.0000, 1.5000])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "#0부터 2까지 0.5씩 증가하는 Tensor 선언\n",
    "x = torch.arange(0, 2, step=0.5)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.]])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#직접 값을 입력하여 선언\n",
    "x = torch.Tensor([[1,2,3],[1,2,3]])\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.]])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#32-bit floating point\n",
    "x = torch.FloatTensor(2,3)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 929181029, 1647129136, 1717842739],\n",
      "        [ 809067061,  778385250, 1952543859]], dtype=torch.int32)\n",
      "Tensor Type :  torch.IntTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#32-bit integer (signed)\n",
    "x = torch.IntTensor(2,3)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Tensor and Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [1 2 3]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#numpy 형식의 배열\n",
    "x = np.array([[1,2,3],[1,2,3]])\n",
    "print(x, type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3]], dtype=torch.int32)\n",
      "Tensor Type :  torch.IntTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#numpy를 tensor로 변환\n",
    "x = torch.from_numpy(x) # x = torch.Tensor(x)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [1 2 3]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#tensor를 numpy로 변환\n",
    "x = x.numpy()\n",
    "print(x, type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Tensor Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모든 원소 출력\n",
    "x[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2행부터 출력\n",
    "x[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  3.,  4.],\n",
       "        [ 6.,  7.,  8.],\n",
       "        [10., 11., 12.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2열부터 출력\n",
    "x[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  7.],\n",
       "        [10., 11.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2행, 2열부터 3열까지 출력\n",
    "x[1:, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1행 출력\n",
    "x[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1., 2., 3., 4.]]), tensor([[5., 6., 7., 8.]]), tensor([[ 9., 10., 11., 12.]]))\n"
     ]
    }
   ],
   "source": [
    "#x를 1행씩 잘라서 배열로 저장\n",
    "x_rows = torch.split(x, split_size_or_sections=1, dim=0)\n",
    "print(x_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 1.,  2.],\n",
      "        [ 5.,  6.],\n",
      "        [ 9., 10.]]), tensor([[ 3.,  4.],\n",
      "        [ 7.,  8.],\n",
      "        [11., 12.]]))\n"
     ]
    }
   ],
   "source": [
    "#x를 2열씩 잘라서 배열로 저장\n",
    "x_cols = torch.split(x, split_size_or_sections=2, dim=1)\n",
    "print(x_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.],\n",
       "         [ 5.,  6.],\n",
       "         [ 9., 10.]]), tensor([[ 3.,  4.],\n",
       "         [ 7.,  8.],\n",
       "         [11., 12.]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#위와 같은 결과\n",
    "torch.chunk(x, chunks=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  5., 10.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_cols의 첫번째 배열 중 특정 부분만 추출하기\n",
    "torch.masked_select(x_cols[0], torch.BoolTensor([[0,1],[1,0],[0,1]]).bool())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Tensor Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_rows를 행으로 이어 붙이기\n",
    "torch.cat(x_rows, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_rows를 열로 이어 붙이기\n",
    "torch.cat(x_rows, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.],\n",
      "         [ 5.,  6.],\n",
      "         [ 9., 10.]],\n",
      "\n",
      "        [[ 3.,  4.],\n",
      "         [ 7.,  8.],\n",
      "         [11., 12.]]])\n"
     ]
    }
   ],
   "source": [
    "#x_cols를 쌓아올리기\n",
    "x_new = torch.stack(x_cols, dim=0)\n",
    "print(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Tensor Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.],\n",
       "        [ 7.,  8.,  9.],\n",
       "        [10., 11., 12.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4행 3열로 바꾸기\n",
    "x.view(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 3.,  4.],\n",
       "        [ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.],\n",
       "        [11., 12.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2열로 바꾸기\n",
    "x.view(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.]],\n",
       "\n",
       "        [[ 7.,  8.,  9., 10., 11., 12.]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(2, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [ 7.,  8.,  9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#차원이 1인 값을 축소\n",
    "x.view(2, 1, -1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.]],\n",
       "\n",
       "        [[ 7.,  8.,  9., 10., 11., 12.]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dim=1 자리에 차원을 추가\n",
    "x.view(2, 1, -1).squeeze().unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Tensor Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "y : tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "y = torch.Tensor([[1,1,1],[2,2,2]])\n",
    "print(\"x :\", x)\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z : tensor([[2., 3., 4.],\n",
      "        [6., 7., 8.]])\n",
      "x+y : tensor([[2., 3., 4.],\n",
      "        [6., 7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# x와 y의 합\n",
    "z = torch.add(x, y)\n",
    "print(\"z :\", z)\n",
    "print(\"x+y :\", x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.,  0.,  1.],\n",
      "        [ 2.,  3.,  4.]])\n",
      "tensor([[ 2.,  4.,  6.],\n",
      "        [ 8., 10., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# x의 모든 원소에서 2를 뺌\n",
    "print(x - 2)\n",
    "\n",
    "# x의 모든 원소에 2를 곱함\n",
    "print(2*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z : tensor([[ 1.,  2.,  3.],\n",
      "        [ 8., 10., 12.]])\n",
      "x*y : tensor([[ 1.,  2.,  3.],\n",
      "        [ 8., 10., 12.]])\n"
     ]
    }
   ],
   "source": [
    "#x의 원소와 y의 원소를 각각 곱함\n",
    "z = torch.mul(x, y)\n",
    "print(\"z :\", z)\n",
    "print(\"x*y :\", x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z : tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.]])\n",
      "x**2 : tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.]])\n"
     ]
    }
   ],
   "source": [
    "#x의 원소를 각각 제곱함\n",
    "z = torch.pow(x, 2)\n",
    "print(\"z :\", z)\n",
    "print(\"x**2 :\", x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z : tensor([[0.0000, 0.6931, 1.0986],\n",
      "        [1.3863, 1.6094, 1.7918]])\n",
      "x.log() : tensor([[0.0000, 0.6931, 1.0986],\n",
      "        [1.3863, 1.6094, 1.7918]])\n"
     ]
    }
   ],
   "source": [
    "#x의 원소에 log를 씌움\n",
    "z = torch.log(x)\n",
    "print(\"z :\", z)\n",
    "print(\"x.log() :\", x.log())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z : tensor([[1.0000, 1.4142, 1.7321],\n",
      "        [2.0000, 2.2361, 2.4495]])\n",
      "x.sqrt() : tensor([[1.0000, 1.4142, 1.7321],\n",
      "        [2.0000, 2.2361, 2.4495]])\n"
     ]
    }
   ],
   "source": [
    "#x의 원소에 루트를 씌움\n",
    "z = torch.sqrt(x)\n",
    "print(\"z :\", z)\n",
    "print(\"x.sqrt() :\", x.sqrt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1.],\n",
      "        [0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#x의 원소에 나머지(mod) 계산\n",
    "z = x % 2\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z : tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "x.abs() : tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "#x에 절댓값\n",
    "z = torch.abs(x)\n",
    "print(\"z :\", z)\n",
    "print(\"x.abs() :\", x.abs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Tensor Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "y : tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "y = torch.Tensor([[1,1,1],[2,2,2]])\n",
    "print(\"x :\", x)\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]], dtype=torch.int32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type(torch.IntTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]], dtype=torch.int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 Tensor Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.,  2., -3.],\n",
      "        [ 4., -5.,  6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[-1,2,-3],[4,-5,6]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x의 합 : tensor(3.)\n",
      "x의 최대값 : tensor(6.)\n",
      "x의 최소값 : tensor(-5.)\n",
      "x의 분산 : tensor(17.9000)\n"
     ]
    }
   ],
   "source": [
    "print(\"x의 합 :\", x.sum())\n",
    "print(\"x의 최대값 :\", x.max())\n",
    "print(\"x의 최소값 :\", x.min())\n",
    "print(\"x의 분산 :\", x.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar Tensor\n",
    "x.sum().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x의 합 : 3.0\n",
      "x의 최대값 : 6.0\n",
      "x의 최소값 : -5.0\n",
      "x의 분산 : 17.899999618530273\n"
     ]
    }
   ],
   "source": [
    "# item의 활용\n",
    "print(\"x의 합 :\", x.sum().item())\n",
    "print(\"x의 최대값 :\", x.max().item())\n",
    "print(\"x의 최소값 :\", x.min().item())\n",
    "print(\"x의 분산 :\", x.var().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4., 2., 6.]), tensor([1, 0, 1]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#행(dim=0)을 기준으로 열의 최댓값을 출력\n",
    "value, index = x.max(dim=0)\n",
    "value, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 6.]), tensor([1, 2]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#열(dim=1)을 기준으로 행의 최댓값을 출력\n",
    "value, index = x.max(dim=1)\n",
    "value, index\n",
    "\n",
    "# torch.max(x, dim=1)과 같은 결과\n",
    "# 이는 추후에 계속 등장하므로 매우 중요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3., -1.,  2.],\n",
       "        [-5.,  4.,  6.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#열(dim=1)을 기준으로 각 행을 정렬\n",
    "value, index = x.sort(dim=1)\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10 Tensor *_like function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.,  2., -3.],\n",
      "        [ 4., -5.,  6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[-1,2,-3],[4,-5,6]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.zeros_like(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.ones_like(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1168, 0.6319, 0.0703],\n",
      "        [0.1896, 0.7902, 0.7531]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand_like(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11 Tensor for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3],[1,2,3]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 Cuda 사용 가능한 Device 개수 : 1\n",
      "현재 Cuda 사용 가능 여부 : True\n",
      "현재 사용 중인 Cuda Device : 0\n",
      "현재 Cuda Device 이름 : GeForce RTX 2080\n",
      "현재 Cuda Device의 사용 가능한 메모리 : 0 bytes\n",
      "현재 Cuda Device의 사용 중인 메모리 : 0 bytes\n"
     ]
    }
   ],
   "source": [
    "# cuda 확인\n",
    "print(\"현재 Cuda 사용 가능한 Device 개수 :\", torch.cuda.device_count())\n",
    "print(\"현재 Cuda 사용 가능 여부 :\", torch.cuda.is_available())\n",
    "print(\"현재 사용 중인 Cuda Device :\", torch.cuda.current_device())\n",
    "print(\"현재 Cuda Device 이름 :\", torch.cuda.get_device_name(0))\n",
    "print(\"현재 Cuda Device의 사용 가능한 메모리 :\", torch.cuda.max_memory_allocated(device=0), \"bytes\")\n",
    "print(\"현재 Cuda Device의 사용 중인 메모리 :\", torch.cuda.memory_allocated(device=0), \"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda 세팅\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.]], device='cuda:0')\n",
      "Tensor Type :  torch.cuda.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#cpu를 gpu로 전환\n",
    "gpu_x = x.cuda()\n",
    "print(gpu_x)\n",
    "print(\"Tensor Type : \", gpu_x.type())\n",
    "print(\"Tensor Size : \", gpu_x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.]], device='cuda:0')\n",
      "Tensor Type :  torch.cuda.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#cpu를 gpu로 전환 2\n",
    "device = torch.device(\"cuda\")\n",
    "gpu_x = x.to(device)\n",
    "print(gpu_x)\n",
    "print(\"Tensor Type : \", gpu_x.type())\n",
    "print(\"Tensor Size : \", gpu_x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.]])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#gpu를 cpu로 전환\n",
    "x = gpu_x.cpu()\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.]])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#gpu를 cpu로 전환 2\n",
    "device = torch.device(\"cpu\")\n",
    "x = gpu_x.to(device)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected device cuda:0 but got device cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-8f59ed9ccba0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# gpu tensor와 cpu tensor의 연산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgpu_x\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: expected device cuda:0 but got device cpu"
     ]
    }
   ],
   "source": [
    "# gpu tensor와 cpu tensor의 연산\n",
    "gpu_x + x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12 Tensor Calculation as Matrix (참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : tensor([[1., 1.],\n",
      "        [2., 2.]])\n",
      "y : tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,1],[2,2]])\n",
    "y = torch.Tensor([[1,2],[3,4]])\n",
    "print(\"x :\", x)\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  6.],\n",
       "        [ 8., 12.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x와 y의 행렬곱\n",
    "torch.mm(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x와 z의 행렬벡터곱\n",
    "z = torch.Tensor([1, 2])\n",
    "torch.mv(x, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#z와 z의 내적\n",
    "torch.dot(z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [1., 2.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x의 전치(transpose)\n",
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0000,  1.0000],\n",
       "        [ 1.5000, -0.5000]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y의 역행렬(inverse)\n",
    "y.inverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 3])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서의 배치 행렬곱\n",
    "x1 = torch.FloatTensor(3,3,2)\n",
    "x2 = torch.FloatTensor(3,2,3)\n",
    "\n",
    "torch.bmm(x1,x2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[8.4490e-39, 1.0102e-38],\n",
       "         [9.0919e-39, 1.0102e-38],\n",
       "         [8.9082e-39, 8.4489e-39]],\n",
       "\n",
       "        [[9.6429e-39, 8.4490e-39],\n",
       "         [9.6429e-39, 9.2755e-39],\n",
       "         [1.0286e-38, 9.0919e-39]],\n",
       "\n",
       "        [[8.9082e-39, 9.2755e-39],\n",
       "         [8.4490e-39, 1.0194e-38],\n",
       "         [9.0919e-39, 8.4490e-39]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[8.4490e-39, 9.6429e-39, 8.9082e-39],\n",
       "         [9.0919e-39, 9.6429e-39, 8.4490e-39],\n",
       "         [8.9082e-39, 1.0286e-38, 9.0919e-39]],\n",
       "\n",
       "        [[1.0102e-38, 8.4490e-39, 9.2755e-39],\n",
       "         [1.0102e-38, 9.2755e-39, 1.0194e-38],\n",
       "         [8.4489e-39, 9.0919e-39, 8.4490e-39]]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서의 전치\n",
    "x1.transpose(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalue : tensor([[1.1921e-07, 0.0000e+00],\n",
      "        [3.0000e+00, 0.0000e+00]])\n",
      "eigenvector : tensor([[-0.7071, -0.4472],\n",
      "        [ 0.7071, -0.8944]])\n"
     ]
    }
   ],
   "source": [
    "eigenvalue, eigenvector = torch.eig(x,eigenvectors=True)\n",
    "print(\"eigenvalue :\", eigenvalue)\n",
    "print(\"eigenvector :\", eigenvector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : tensor([[-0.4472, -0.8944],\n",
      "        [-0.8944,  0.4472]])\n",
      "R : tensor([[-2.2361e+00, -2.2361e+00],\n",
      "        [ 0.0000e+00,  7.3940e-08]])\n"
     ]
    }
   ],
   "source": [
    "#행렬의 QR factorization\n",
    "Q,R = torch.qr(x)\n",
    "print(\"Q :\", Q)\n",
    "print(\"R :\", R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S : tensor([[-0.4472, -0.8944],\n",
      "        [-0.8944,  0.4472]])\n",
      "V : tensor([3.1623e+00, 5.2283e-08])\n",
      "D : tensor([[-0.7071, -0.7071],\n",
      "        [-0.7071,  0.7071]])\n"
     ]
    }
   ],
   "source": [
    "#행렬의 SVD factorization\n",
    "S,V,D = torch.svd(x)\n",
    "print(\"S :\", S)\n",
    "print(\"V :\", V)\n",
    "print(\"D :\", D)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
